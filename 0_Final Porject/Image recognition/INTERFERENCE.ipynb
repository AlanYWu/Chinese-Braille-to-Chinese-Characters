{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 001111s, 2 010100s, 2 010110s, 1 011100, 1 011110, 2 100000s, 4 100010s, 2 100100s, 4 100110s, 1 101001, 1 101010, 1 101011, 1 101100, 1 101101, 1 101110, 2 110000s, 2 110010s, 2 110100s, 2 110110s, 2 111000s, 1 111001, 2 111010s, 1 111100, 1 111110, 1435.0ms\n",
      "Speed: 16.9ms preprocess, 1435.0ms inference, 13.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "1 label saved to runs\\detect\\predict\\labels\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "e:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\Chinese-Braille-to-Chinese-Characters\\0_Final Porject\\Image recognition\n",
      "⠁⠃⠉⠙⠋⠑⠋⠙⠛⠓⠑⠊\n",
      "⠓⠇⠇⠍⠝⠕⠏⠟⠗\n",
      "⠎⠞⠥⠼⠗⠭⠵\n",
      "⠧⠼⠚⠁⠃⠉⠙⠑⠙⠛⠚⠊⠑\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from ultralytics import YOLO\n",
    "import src\n",
    "from src.convert import convert_to_braille_unicode, parse_xywh_and_class\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"load model from path\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    return model\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"load image from path\"\"\"\n",
    "    image = PIL.Image.open(image_path)\n",
    "    return image\n",
    "\n",
    "# constants\n",
    "CONF = 0.15 # or other desirable confidence threshold level\n",
    "MODEL_PATH = \"./weights/yolov8_braille.pt\"\n",
    "IMAGE_PATH = \"./assets/alpha-numeric.jpeg\"\n",
    "\n",
    "# receiving results from the model\n",
    "image = load_image(IMAGE_PATH)\n",
    "model = YOLO(MODEL_PATH)\n",
    "res = model.predict(image, save=True, save_txt=True, exist_ok=True, conf=CONF)\n",
    "boxes = res[0].boxes  # first image\n",
    "list_boxes = parse_xywh_and_class(boxes)\n",
    "\n",
    "result = \"\"\n",
    "for box_line in list_boxes:\n",
    "    str_left_to_right = \"\"\n",
    "    box_classes = box_line[:, -1]\n",
    "    for each_class in box_classes:\n",
    "        str_left_to_right += convert_to_braille_unicode(model.names[int(each_class)])\n",
    "    result += str_left_to_right + \"\\n\"\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  Ultralytics settings reset to defaults. This is normal and may be due to a recent ultralytics package update, but may have overwritten previous settings. \n",
      "View and update settings with 'yolo settings' or at 'C:\\Users\\Lenovo\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n",
      "2023-11-20 14:56:23.687 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run d:\\Anaconda3\\envs\\braille\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "d:\\Anaconda3\\envs\\braille\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "yolov8m.pt: 100%|██████████| 52.1M/52.1M [00:46<00:00, 1.13MB/s]\n",
      "d:\\Anaconda3\\envs\\braille\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load model='snoop2head/yolov8m-braille'. As an example try model='yolov8n.pt' or model='yolov8n.yaml'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './images/alpha-numeric.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\DotNeuralNet\\src\\INTERFERENCE.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mif\u001b[39;00m source_img \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     default_image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./images/alpha-numeric.jpeg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     image \u001b[39m=\u001b[39m load_image(default_image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     st\u001b[39m.\u001b[39mimage(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         default_image_path, caption\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExample Input Image\u001b[39m\u001b[39m\"\u001b[39m, use_column_width\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32me:\\BaiduSyncdisk\\3课外活动\\科研实践 盲汉翻译\\DotNeuralNet\\src\\INTERFERENCE.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(image_path):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"load image from path\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     image \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39;49mImage\u001b[39m.\u001b[39;49mopen(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BaiduSyncdisk/3%E8%AF%BE%E5%A4%96%E6%B4%BB%E5%8A%A8/%E7%A7%91%E7%A0%94%E5%AE%9E%E8%B7%B5%20%E7%9B%B2%E6%B1%89%E7%BF%BB%E8%AF%91/DotNeuralNet/src/INTERFERENCE.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m image\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\braille\\lib\\site-packages\\PIL\\Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3240\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3242\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3243\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3244\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3246\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/alpha-numeric.jpeg'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reference\n",
    "- https://docs.streamlit.io/library/api-reference/layout\n",
    "- https://github.com/CodingMantras/yolov8-streamlit-detection-tracking/blob/master/app.py\n",
    "- https://huggingface.co/keremberke/yolov8m-valorant-detection/tree/main\n",
    "- https://docs.ultralytics.com/usage/python/\n",
    "\"\"\"\n",
    "import time\n",
    "import PIL\n",
    "\n",
    "import streamlit as st\n",
    "import torch\n",
    "from ultralyticsplus import YOLO, render_result\n",
    "\n",
    "from convert import convert_to_braille_unicode, parse_xywh_and_class\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"load model from path\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"load image from path\"\"\"\n",
    "    image = PIL.Image.open(image_path)\n",
    "    return image\n",
    "\n",
    "\n",
    "# title\n",
    "st.title(\"Braille Pattern Detection\")\n",
    "\n",
    "# sidebar\n",
    "st.sidebar.header(\"Detection Config\")\n",
    "\n",
    "conf = float(st.sidebar.slider(\"Class Confidence\", 10, 75, 15)) / 100\n",
    "iou = float(st.sidebar.slider(\"IoU Threshold\", 10, 75, 15)) / 100\n",
    "\n",
    "model_path = \"snoop2head/yolov8m-braille\"\n",
    "\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    model.overrides[\"conf\"] = conf  # NMS confidence threshold\n",
    "    model.overrides[\"iou\"] = iou  # NMS IoU threshold\n",
    "    model.overrides[\"agnostic_nms\"] = False  # NMS class-agnostic\n",
    "    model.overrides[\"max_det\"] = 1000  # maximum number of detections per image\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    st.write(f\"Unable to load model. Check the specified path: {model_path}\")\n",
    "\n",
    "source_img = None\n",
    "\n",
    "source_img = st.sidebar.file_uploader(\n",
    "    \"Choose an image...\", type=(\"jpg\", \"jpeg\", \"png\", \"bmp\", \"webp\")\n",
    ")\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "# left column of the page body\n",
    "with col1:\n",
    "    if source_img is None:\n",
    "        default_image_path = \"./images/alpha-numeric.jpeg\"\n",
    "        image = load_image(default_image_path)\n",
    "        st.image(\n",
    "            default_image_path, caption=\"Example Input Image\", use_column_width=True\n",
    "        )\n",
    "    else:\n",
    "        image = load_image(source_img)\n",
    "        st.image(source_img, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "# right column of the page body\n",
    "with col2:\n",
    "    with st.spinner(\"Wait for it...\"):\n",
    "        start_time = time.time()\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            res = model.predict(\n",
    "                image, save=True, save_txt=True, exist_ok=True, conf=conf\n",
    "            )\n",
    "            boxes = res[0].boxes  # first image\n",
    "            res_plotted = res[0].plot()[:, :, ::-1]\n",
    "\n",
    "            list_boxes = parse_xywh_and_class(boxes)\n",
    "\n",
    "            st.image(res_plotted, caption=\"Detected Image\", use_column_width=True)\n",
    "            IMAGE_DOWNLOAD_PATH = f\"runs/detect/predict/image0.jpg\"\n",
    "\n",
    "    except Exception as ex:\n",
    "        st.write(\"Please upload image with types of JPG, JPEG, PNG ...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    st.success(f\"Done! Inference time: {time.time() - start_time:.2f} seconds\")\n",
    "    st.subheader(\"Detected Braille Patterns\")\n",
    "    for box_line in list_boxes:\n",
    "        str_left_to_right = \"\"\n",
    "        box_classes = box_line[:, -1]\n",
    "        for each_class in box_classes:\n",
    "            str_left_to_right += convert_to_braille_unicode(\n",
    "                model.names[int(each_class)]\n",
    "            )\n",
    "        st.write(str_left_to_right)\n",
    "except Exception as ex:\n",
    "    st.write(\"Please try again with images with types of JPG, JPEG, PNG ...\")\n",
    "\n",
    "with open(IMAGE_DOWNLOAD_PATH, \"rb\") as fl:\n",
    "    st.download_button(\n",
    "        \"Download object-detected image\",\n",
    "        data=fl,\n",
    "        file_name=\"image0.jpg\",\n",
    "        mime=\"image/jpg\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braille",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
